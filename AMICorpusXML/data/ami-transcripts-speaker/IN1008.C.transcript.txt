Okay. Should I start? Maybe by presenting the project little bit. Okay, so historically it was um uh last year Prof Delambeaux in uh his C_S_C_W_ classes uh asked the student to design a table. And all the students, and Guillaume wa was a student of this class, was very excited uh to design such a table. So he decided to um to make more research on this topic. So the general topic uh is about uh interactive table, um disappearing computer, um what is the other one. Um um na uh in the general fi field of uh collaborative computer supported collaborative learning. So the idea is we have different people collaborating uh in a pedagogical purpose. And uh we know that when we put a computer in front of them, uh it doesn't help focusing on collaboration. So if we make the computing um functionalities disappearing on on the in the furniture, in the wall or other things like that, we may more efficiently support uh collaboration than the the learning. So I arrived uh in June, something like that, a couple of month ago. Uh Guillaume and uh Michael uh are two students that are working uh four four months to their master project. And they start working on two uh different uh sub-projects. So Guillaume is working on the noise sensitive table. It's uh what we are discussing about uh today. So the idea is uh okay, w we have in the lab a notion about um root mirroring. The idea is if we can provide a feedback to people working together, uh it may help them self-regulating their activity, their collaboration. So could be normative or not. In our own case we want to have uh a table that would be accessible by by students. Uh at O_P_F_L_ we are uh At O_P_F_L_ uh the learning centre will be built in a couple of uh years. So the idea we we will have plenty of rooms uh like in libraries or meeting rooms where student will arrive and work. So if we have this table uh that is accesi accessible to students if they arrive, if we provide a feedback of um who is talking, um instantly the uh at one moment or uh through time or the turn taking, uh maybe they will just by seeing an explicit uh feedback of that, they will um take profit uh of it and um Yes. The idea is to have uh peripher peripherical uh information. We don't want people to focus on uh what's going on, uh what on the feedback. So we don't want histogram or very precise information. But we will uh have LEDs that will be distant. There will be six centimetres between each LED with a blurring glass. The idea is to have more um a kind of uh art, artistic uh feedback, to have a kind of general feeling of what's going on. Something about Uh dance. For practical reasons. We kept uh one paper sheet. So uh the first shape of the table the shape of the table obviously is one of the factor on that will change the collaboration. So uh but we don't want to start with too many parameters. So we start with a table that is approximatively the tab uh of the table where we are now. And we will have uh a square shape like this that will be here and a second one that would be there. So we will have something like this. Like this. That will be the our first uh real prototype. Okay. And the so this L_E_D_ modules are being uh designed uh now. We should have them in a couple of weeks. And uh we will be able to uh start uh evaluating uh the prototypes. Uh uh about the C_S_C_W_ class, that will start at the end at the beginning of November. Uh so the student will be asked to design uh a table. So to find the shape uh of the table to get uh who the and put that uh on the um on table uh legs. And we will uh so at the beginning we wanted to put this L_E_D_ modules uh in the tables. But we won't make it because uh for solidity reason of the table. You know, it's not very uh strong uh wood. Um so we will rather beam uh the L_E_D_ on the table. So we come back to a more richer display. B but we will um restrict it to a small uh to have the same display. LED lights uh that will be distant uh six centimetres between LEDs. So we will simulate our And we have yeah. And we have the feeling that to have the information embedded in the table, make it part of the table, it I don't know, we'll we we will try uh we don't really know what uh will happen with this prototype. We are very excited about that. Okay, uh maybe before uh going on on this subject we can talk talk a little bit on uh Huh. So based on the fact that most of the P_F_L_ student have their own laptop uh the idea is the similar idea uh is to okay, people are coming on a should be able to very easily uh use some um resources offered to them. So so the idea is to help them socialising, organising their own work, and uh not in a classroom setting, but in a social place where they could gather. Different directions. Okay. So uh maybe we can focus a little uh uh bit more on the what we have done about uh the noise sensitive table. Tell you about uh what we're interested in on the so we start so Guillaume started by uh developing the application that get the audio input. So we want it to have a modular architecture to be able to improve each uh layer separately. So the audio input uh is quite basic, no? We u we use uh sound cards to to get uh the signals and to detect to uh on to ha and we have a threshold to detect uh when someone is talking, at least when the noise is uh at uh is bigger that uh specific levels. And then we get this information about people talking, not talking, and to say okay uh, this one is talking for X_ time or uh has been talking uh X_ percent of the five last minutes. Or two people are talking together. So this is more semantic uh layer. Uh we call that interaction uh models. And uh uh so when different conditions are trigger are detected, we trigger on the interaction event. So very simple one could be one person is talking. So it's uh the easy one. It's still in progress. Still in progress. So the last layer is about this visualisation. W we will uh we are thinking about the visual grammar, meaning that when we have an interaction event that is uh fired, we uh will associate uh a way of visuali visualising it. So for instance if someone is talking, uh we can just have a light that will centre on the point that is uh close to him. That could be an uh instant uh feedback. And if he has been talking maybe seventy percent of the last five minutes, as me, uh uh it it may be reflected as the um intensity or size of a s a cycle. Centre on the same point. And then if there's turn taking, we can show waves of light going from uh me to you uh or from other people. Or using the centre part of the table to show some something more about the um uh more general uh dynamic. Or laughing. Yes. In uh we can change inte so we have uh eight by eight uh two times LEDs. Each uh LED is actually three LEDs um. Th uh M_G_B_ LED. And we can change the intensity. So it's already quite a rich uh feedback. Yes. And just a last thing. So this table is uh two different things. It's uh one object that will uh g provide a feedback to the terminal users, people collaborating around uh the table. But it also a tool for us as a researcher to test uh both the interaction event we want to detect and to test the visualisation. So um we will be able to edit some uh interaction rules and the visualisation uh grammar. And uh we will be able to process to post-process some conversation just to see what happens and to uh have these um models on feedback working when people are using the table. So I think it was Yes. Um Maybe we could summarise the question we were thinking about. So basically what we want we want to know when A_ is talking, B_ is talking and uh Basic information we need.. Maybe we can uh go through the different questions and then you can organise your own? Um I would just add something. Uh we are not interested so much in sound level but uh in the level of uh the sound that corresponds to voice. Mm-mm. Okay, it was just a Okay. Go on. And I would add uh one more. It's about um because what we can uh record is uh sound uh origins. So in po uh so no sonic points. But what we are interested in is people. So the question is if someone is moving, I'm talking here, I stop talking, I'm going here, I'm talking. How to detect that it's the same people. If we want to uh integrate information to say these people has uh spoken seventy percent of the time in the five last minutes. Obviously we need to uh to know that it's the same people. So right now our practical solution is to have one uh microphone close to um every place where people are supposed to sit. So we can infer that if a sound is coming in this area, it's the same. So kind of trick. But for the beginning it's enough. And a last question that is related t uh our last if I not find another one, um About people, if someone is leaving or if someone uh maybe it would be something ev uh quite complex even for you. If someone is staying here, but is quiet or leaving, how can we detect that someone is here but quiet? Okay. I know. But how to integrate the information? Uh Not not yet. Maybe later on. But Oh, the wait and the sit.. Or putting his bag on the okay. But it was just to it's a question. I'm not sure we will talk too much about that today. Uh not directly. But it's uh related. So in a couple of days we will get this um uh the fire-wire uh box. So we will we have chosen one that has eight uh line up. So we'll be able to have line in, sorry. So we will be able to plug uh up to eight uh microphones with uh jack plugs to exhale air with the possibility of extending with eight more X_L_R_ uh microphone with another box. So we ha we have the computer, we have the the main box with the eight line ins. And it's fire-wire. It is optic. To have eight more X_L_R_ if we need it. But we are not sure to to buy it now. But we can extend it. That's uh Yes. Well We are not sure about what kind of microphone we should use. So we wanted to uh that's a first thing. So we wanted to have open possibilities. And secondly, maybe we will use this box, you know, to get uh data. I don't know if in another experiment, maybe in another project, if we want to have comments of different people around the table or o elsewhere. Uh getting uh having the possibility of using X_L_R_ microphone could be uh uh could be neat. So everything is open. No, we are not very interested in. More than one Mm-mm mm-mm. Okay. They won't have nice light uh lighting on in front of them. they would maybe careful. But Okay. So maybe w uh you could present a different work uh you have done. And uh I don't know how they are. So you told us it was different pieces, more than one integrated device. Oh uh What would be the d difference between detecting the average or detecting the maximum? What what would be the difference? What is the difference? It's a kind of filtering already? Sixty? Okay. again. Uh-huh. Okay. So it's thirty two millisecond frames taken each An idea. So something like that. So why are you overlapping? I have a rough idea. But uh what is the main interest? Mm-hmm. Yeah, and it's kind of crappy. Precise. Okay. Okay. Mm mm mm. So you use the first and last point to detect what is between. Mm-hmm. Mm-mm. Okay. So you are Mm-hmm. Mm-hmm. Corresponding to breath or a little noise. 'Kay. But you're talking about the microphone array here? Strong background noise. So phase Uh-huh. Uh-huh. Okay. So the phase the time between uh audio signals for um for this microphone on this microph Okay. Okay. Mm-hmm. Mm-hmm. And do you get something about the um distance of the guy that is talking, or just a direction? Okay. Mm-mm. Mm-hmm. Okay. You mean that each person will have a specific frequency because i the way he's talking or his localization? It's a kind of uh speaking styles? Both. I don't really get your last uh diagram, yes. So it's at one given moment still? Okay, so you can say that f this frequency belongs more to this person and this one more to this one? But some frequency may maybe are not used neither by uh guy the guy one or the guy two. Okay. maybe they are using the same frequency. so you need to s Okay. Okay. Okay. And can you detect if someone is laughing or angry d uh there is kind of signature uh even if we can't really trust it uh uh s one hundred percent of the time. Uh And do processing on it. Okay. Pitch. It is pitch. Li okay. What is a? Excuse me? Uh-huh. Okay. Okay. So where are you represent the phase?. Okay. Uh-huh. Uh-huh. Okay. Mm-hmm. Mm-hmm. Mm mm mm. Because if we are distributing the microphone all around the table, then we come back to the energy solution? Is it what you say? With the energy dissolution or with uh F_F_T_ too? Okay. But there are many many things. The difference between the Mm-hmm. Mm mm yeah. What would be the difference? You will not compare each mic with uh all the other one. But just comparing this one with the Mm okay. Okay. But what are uh-uh. So what are this mic for instance, the electret mic. Omni-directional? Electret? Okay. Yes. And when you were talking about comparing energy in the case where a microphone would be distributed all around the table, uh you're comparing energy and the time delay? Because time delay is is too short to be compared or can be neglected? Okay. Okay, okay. Yeah. It's time. Cool.