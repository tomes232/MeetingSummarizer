Oh my God. Yeah.. Okay. I should start? Yeah, no so I thought that we might s t speak a little bit about speech coding because nobody is doing here speech coding and I would like to have some maybe feedback because except me. I've I've supposed to some speech coding stuff here with Hynek uh but you know that little bit at least that uh based on some let's say Hilbert transforms using a longer temporal context and deriving some parameters would be tranf transcs transmitted to a decoder and So it's a little bit different than the stuff which people are using now, which is like a L_P_C_ based. And but we are at the beginning with everything more or less. So still um we can't uh d encode a speech. But of course there is there are many problems which we still didn't solve and the biggest one is quite similar to L_P_C_ stuff where people still don't know how to exactly encode a carrier or the source signal. We know what to do with the envelope or how to approximate the envelope, let's say. Um when you have got Oh you mean that it would be nice to plot at least s Um maybe I I can I can So what we are doing now, yeah, you mean. Okay, i uh everybody knows L_P_C_ stuff, how it works. So I don't have to present anything mores. But it's uh m more or less very simple. We have let's say at the beginning there is some speech signal. What we are uh we might see it uh in very simple way that we are using some Hilbert transform h at the beginning to create analytic signal. The analytic signal is the signal which is a complex which you can create from the uh real uh uh some sequence. And if you get if you apply Hilbert transform on this, on such a speech signal, like a real trajectory, then you get a complex signal and if you take just the amplitude, then you get Hilbert envelope code. So I well I I don't know. Yeah, let's say ups. Yeah, it's u it's not P_L_P_ at all, d Mm. No he's it's pretty much the same. Uh you're lit I know what you mean with the pu P_L_P_. They are applying P_L_P_ with some iteration with this this one approach. So they are doing some smoothing of a spectrogram in two ways. One was right. Right. But P_L_P_ is using just the spectral uh direction. Let's say you are doing uh for every twenty millisecond processing one one feature vector. Here you are processing one spectral band, frequency band, right. So it's different direction which we are w using. But anyway, this is very simple. So applying that uh absolute uh absolute operation, you get a Hilbert envelope. And of course then there is the phase. So it's just the complex operation. And that's more or less all what we are doing. So now what we know what we know is how to approximate that Hilbert envelope. We are ap we are applying that Hilbert uh him what is the Marius' uh stuff. So he knows how to encode uh the Hilbert uh envelope using like L_S_F_s or L_P_C_. You are applying again to some linear prediction model after that. But it's uh right, it's in a it's a little bit difference in not applied in the frequency domain. So instead of classical L_P_C_ domain, where you have a spectrum, let's say something like that, and you are applying some linear prediction model which is trying to approximate the spectrum, right. So this is frequency. In our case we are we are trying to approximate s kind of instantaneous energy. So if this is a time, and you get one and add one frequency band, you can see something like this. And we are trying to approximate that envelope which is that Hilbert envelope. Right? So again, we know what to more or less we know what to do with the Hilbert envelope. We know that we can apply linear prediction model and it works pretty well. But i if you want to really construct the speech signal or the you need also the phase signal, which is in uh some sense quite simple for voiced speech signal, say. But s uh the phase no, you ac It's a phase or you can encode it like a carrier. So the carrier is, if you know, uh amplitude modulation, right? You may see something like there is one cosine which is uh very would have quite a f right. Yeah. It's called like the phase. Right, right. Exactly. So the this is the signal which you also have to somehow encode or transmit from a code of the decoder in order to re-synthesize it, right. So What do you mean? Again. For this one? For the the linear prediction model? Well it's uh just a linear prediction. Classical way. I mean oh, okay, w well, if you want to see it in more details, I mean Oh, you mean uh yeah, bit bit rate you mean? Okay, yeah. Sure, sure. So whereas we are what we are now is, let's say, something like one point two kilo-bits per second for uh that Hilbert envelope. Is It's again a roughly estimated somehow. But we still know that we can go down and right. Exactly, yeah. I don we are using like fifteen bands. Right. But they are first they are inter oh well, integrated into fifteen bands using oh classical way like in M_F_C_C_s or in P_L_P_. You just apply some those uh triangular windows or something like that in order to to get a li really like just fifteen bands, right. And each band is then processed independently. So for one band we more or less have w like w one hundred bits per second. For Hilbert envelope. Right. Right, right. You yeah, you can just right. Right. Right. Yeah. Uh right, that's what we did. Yeah, sure. Sure, sure. Yeah. There are many things we would wouldn't at all. But yeah, exactly. But now what I r really trying to do is somehow approximate that uh carrier signal, to do something with the carrier. There are many simple things which you can do like uh quantization quantization, for example. Right. You mean something like uh f uh that CELP coding system where you're or wh wh wh what is no, what is exactly scalable system? What you mean by that? Oh yeah, yeah, sure. This was yeah. For dif yeah, right. Right, right. Yeah. But I think this appr approach can do that because you really can split it into several bands. And you can decide how many bands you want more or less. So Yeah, this is a bar scale we are using. Yeah, or Mel Mel scale, so it's uh it's being uh more wider for higher frequencies and of course the s the spaces right. Yeah. But what I w my sense is that it is not so much important still. I mean it doesn't matter if you're als use Mel scale or bar scale. But right, yeah. But that's what we are using, yeah. Uh actually we are using just Gaussian windows here instead of those triangulars because they are more uh no, it's better than for decoding it's better to play with them because they they are not zero anywhere, you know. They are they are approaching or in they are in zero. But actually they are not. So d you don't have to care about some zero values here and but more or less it doesn't matter, yeah. We are using just Gaus Gaussian windows. Okay, so l those are that the Hilbert envelope is um is approximated by linear prediction. So you have L_P_C_ coefficients which you can transcribe into L_ L_ L_S_F_s, which are right, exactly. Yeah. Right, exactly. So first uh the approach is quite sim simple. So at the beginning we apply D_C_T_ in order to get to frequency domain. Then you apply those uh triangular or Gaussian windows. So this is done for one second, eight thousand samples for eight kilo-hertz sampling frequency, right? So for such D_C_T_ trajectory you apply those uh Gaussian windows. And then i so you split it in two frequency sub-bands. And then each one f frequency sub-band is more or less uh Right. Right. Exactly. You just apply L_ L_P_, so auto-correlation let's say, or you can do power spectrum, whatever. Yeah, so you for each one you get L_S_F_s here. Uh well, I'm using now like twenty L_S_F_s per one second, per one frequency band. Fifteen. No no. If I just keep all them so twenty L_S_F_s, each one is um is quantized by four or five bits. Of what? Three hundred bits? Two. Yeah, yeah. Yeah. Yeah. Exactly. You mean this phase, the the Hilbert carrier? Or no, of course we did Yeah. Uh w well, there are many things you can do. We don't well the first thing what you can really do is just to replace it by Gaussian noise. So you can really use t like in uh L_P_C_ system. Right. Exactly. Or you can replace it by some cosine, one cosine generated in a cen centre frequency of that Gaussian window. Right. Yeah. It mi it mi yeah. Twelve hundred? Yeah. Yeah, it's possible, some of it. Yeah. Mm-hmm. R right. Well I'm just comparing with uh L_P_C_ ten standard, which is like classical L_P_C_. A little bit optimized. So there in the there is I think two point four kilo-bits per second, the bit rate for that. Yeah, definitely. This is no, uh I mean L_P_C_ ten is just L_P_C_. No no no. No. Just noise or just those impulses. CELP. Yeah there yeah, yeah. Yeah. Yeah, yeah. Four point eight or something. Right. Yeah, sure. Well more or less what we didn't do is analysis by synthesis, right. So that's what CELP is doing, right. So yeah, so this is what we do and uh that might help a lot, of course. But w yeah, exactly. That's that's the question. It will be. Yeah, yeah. Yeah, sure. For example, uh there what I also did was uh a simple peak peaking algorithm. So if you take a look on that spectrum of that of that carrier signal, which is more or less like the cosine if you really take a look on that. But it is kind of frequency shifted cosine or frequency modulated cosine. Right, so it's th the frequency still to be changing. Or of course the amplitude is just not constant all time. It should be theoretically. But practically it's not. So what you can see for a one second signal, you m more or less you already might see some like one one uh impulse there or spectral line for. But usually there are many others which are s quite small, but they are quite important. If you don't transmit them, then the signal is quite robotic or something like that. So if you're really transmitting just one spectral line. But this is what you can do. And you can understand pretty well. The signal is audible. Or if you're adjust uh th find one one line, one speaker and dom dom dominant one in the spectrum of that c uh carrier Hil Hilbert carrier, and you just transmit this parameter. No, n It's even easier because what you have to do is just divide the you just multiply that Hilbert envelope by the table carrier. That that's all. Yeah, yeah. Yeah, exactly. So so you just multiply that uh one Hilbert carrier, which is transcribed by L_S_F_s by that this one I_F_F_T_ signal. So Oh f you mean the phase of that uh of that carrier? Of of course I try to play also with that, and uh I found that it doesn't matter so much which what is the phase because we are using just one second window, right. So of course there there might be uh some uh disturb uh disturbed uh when you concatenate those segments together. But then the phase might be important. But otherwise, I mean, I didn't find any anything important with the phase. Like great, keep the phase zero and it works. Or Right. Right right right. Yeah. But it's again a little bit different, because they are i they are doing this in a frequency domain. But this is in time domain, more or less. Right. The spectrogram, you mean. Yeah, yeah, yeah. Yeah. Right. Right. Exactly. What we can also do very simple is just to get the magnitude spectrogram using this approximation without the carrier, just Hilbert envelope. But you just uh get it in in this way, in in the way of Rob's, right. But you can also get the s short time Fourier transform uh and keep it right. Just classical uh frame by frame algorithm, twenty milliseconds. Uh but you keep just the phases instead of magnitudes. And you can put this together, right. And it works pretty well, and then the signal is not uh just uh whispered. Then you really hear that there is the voiceness in the signal. But uh of course the quality is uh is not so good still. But uh you can use it for like two, three kilo-bits per second and it works. Like yeah. Right. Right. Yeah, sure. Anyway, so um hmm m maybe it would be nice if you t if you tell us uh what you do with the speech coding 'cause I d I didn't see any of P_H_D_s of you, I think. So if you did something so maybe it would be interesting at least to Yeah. Yeah, sure. It's true. So you were when when did you do that? Oh okay. Uh-huh. I think so, yeah. You mean using that uh C_D_M_A_? Or Yeah, it's not G_S_M_. Right it's uh kind of s no C_D_M_A_ is uh another level, I think. Mm-hmm. I think there is a l lot of money in that like, right. Like speech recognition, of course it's very interesting, but people don't use it so much as s just coding, just telephoning, right, or just Right. Yeah. They s yeah, yeah. Right. Right. No, I I. Well what we were what we were thinking about is oh, C_D_M_A_, I mean there is the b Well, the problem is this in with this application, or it doesn't have to be problem but one constraint is that we are processing one second of the signal. You can go down of course. But then you are losing little bit of the bit rate, let's say, right. So but there are many applications where you really can use it because you don't care about algorithmic delay, one second algorithmic delay, like for I don't know if instead of S_M_S_ you can really have some channel where you just right. Um so probably. Right, right. Yeah. Right. Yep. Right. What if s Which one, s oh Well, but the sinusoidal coding is usually m when you s at least what I think or uh what I know is when you are doing sinusoidal coding it means you just take the speech signal at the beginning, right. And you are trying to find to uh yeah, to find the harmonics in a temporal domain, right, for that. Right. Oh. Yeah. Right. More or less I did it maybe different way, but kind of algorithm like okay, trying to find out the strongest or the the most dominant peaks in the spectrum, which is more or less the same. But th But you know, the the f the interesting Right. Right, and that that's it. And then you do multiples of right. Yeah. Yeah. Like it If it is unwrap you mean. Unwrap uh phase. Right. You l right, yeah. Yeah, yeah. I also play with that. And for example what I found i well, in this case uh we are not trying to encode the speech signal. We are trying to encode some carrier, which is much easier, I would say, because you can really im you can see that even. So what I was trying to encode at the phases, so I just found that uh two bits is enough for that and you really don't hear the difference. So if you keep all the spectral lines as they were there but you were just uh quantizing with two bits or three bits for amplitude, two bits for for phase. So it's okay. The problem is that you have to transmit many of them. 'Cause there is not just one dominant component but usually more others which are quite small, right. Or what you have to do then you have to decrease the the the size of not one second, but you have to go down because then you can get just voiced part and unvoiced part. You know, one second it's usually mixed right somehow together. Not now, no. I wi Uh uh we don't no want to do that, yeah, because it's quite tricky. Right. yeah, sure. Exactly. Right. But for example what we also found is that if you use just the Hilbert envelope, that that one which is trying to approximate that energy in some low band, like ar around two hundred t uh hertz, and you take a look on the signal, on the trajectory, you can see that it works like kind of um voice detector. Because uh for a low energies there is usually noise. For high energies there is kind of a harmonicity. So it works pretty well for that. So we might use this one information for that. But Yeah, I think so, yeah. Mm-hmm. Right. Uh-huh. Mm-hmm. Mm-hmm. That's true, yeah. Yeah. Yeah, yeah. Yeah, that's that's a problem. Sure. Uh f That would be nice n not to have anything, yeah. Right. Yeah, yeah. My Mm-hmm. Right. Exactly. Well I don't know. Maybe if you we uh really want to improve the the quality, then we will need it, I don't know, still. N not now. Yeah, uh well, I'm gonna t have a time next next month or in three weeks so I'll try to play some examples there for you and What we are trying to reconstr How does it look like or sure. Yeah, more or less. It's kind of uh not frequency. Let's say amplitude modulation when you have ju just the carrier and that modulation signal, right. Yeah, we yeah, yeah, yeah, exactly. Yeah, yeah. It's in between, exactly. So it's not this and that. But still yeah. But anyway what also the other approach which is possible to use. The other is one to keep the phase like this one, like two spectrograms, one the phase and one the magnitude. And well I can again play it and it works on two kilo-bits per second. Quite what uh no, what uh he was doing he was using it for speech recognition, what I what I know, but for speech coding no no no, it was I don't know. For speech coding you mean? I don't know. I don't know. M maybe. Right. Yeah. Mm-hmm. Well for example this phase information right. Yeah, yeah. I think so. There are m more papers which are using this approach, like trying to encode the magnitude spectrum or spectrogram. Uh the phase or you just uh re can again the phase can be replaced by the noise, which is pretty good. So that's uh the benefit uh variable approach. So if you really don't have a band width, you just can replace it by noise and it works. Of course then it doesn't sound as the original because it's more whispered or whatever. But you can understand well. And for example uh if you mention this one approach with the that uh trajectory of the phase, of unwrap phase recre uh I also use because you can do it here when you get into uh this domain where you apply uh or you're trying to compute uh s power spectrum in in order t let's say that this kind of trajectory, it doesn't in fit the same frequency over time domain. But here you are trying to compute uh doing a to do linear prediction. So we are just doing F_F_T_, right. Then applying uh power in order to get um to s to power domain, and then I_F_F_T_, right. So you get the auto-correlation coefficients. So before you're applying uh power spectrum, you can again get the you have got a complex f freq frequency or complex spectrum, you can get the phase, right. And the phase look quite similar like this. So you might see it's is more less like a line. Right. Yeah. Right. Yeah, it's it is very different, yeah. Then you are doing in different domain. I think this is in frequency domain, this in time domain. Um it is quite it's quite sensible to any quantization, what I found. Really it looks like the lines. So you just say okay, let's p let's put the line there. But it doesn't work. Re well, you can understand. But you can here that there are many artifacts which right, exactly. Right, right. And the another problem is that uh it's not band width variable. So you cannot say that this part will be the just the noise, which you can do in here in this this other approach. So that's why I didn't play with that so m more because I found there are more uh disadvantages than the advantages, this approach. So that's why. You mean this one? Yeah, if you take just the original phase and the Right. Yeah, it's it's it's not a phase. Yeah, yeah, yeah. It's the phase no, you can again put the that envelope with this phase together because envelope is twe No no. You g no, you get the f Yeah, you get the complex complex spectrum with this. No, no, I started with the D_C_T_ No, after D_C_T_ you are trying this is so kind of again a real trajectory, right. And you're trying to first find that Hilbert envelope. So uh let's well so this is a speech. No, but here what I want to say is really that y it's not part of Hilbert envelope, it's part of the D_C_T_ signal. So it's not it's enough if you have just this phase and f and the Hilbert envelope, you can put it together. You don't need the carrier. I mean this is kind of a carrier signal but in different domain represented. Right, right. So I what I think is that we already will need to apply s kind of analysis by synthesis approach mm uh in order to get something. Right. What I No. You mean ye Right. Right, right. Yes, that's true. But I mean that's maybe even the advantage here because you it's not speech d based, which means we are not Right. So you can when I tried and comparing with L_P_C_ ten on a uh twice bigger or higher bit rate, this work works better, it seems to me. Just for unvoiced speech. O I'm not mentioning uh voiceless because that's unvoiced, which means whispered. Uh yeah, but uh when you hear and try to use some examples with the music for example Right, yeah. Mm-hmm. That's true, yeah. Uh but anyway, it seemed to me pretty good. I mean that there might be. that's true, yeah. Uh it should be uh thirteenth December I think. I just uh you won't be here. Uh okay. No, I just swapped it with uh Mike Perrot I think 'cause h he is not going to be here this time. And I was supposed to have it in uh in January. So whatever. Anyway. So But anyway, I I wanted to hear something maybe from you what you are doing f with speech coding because you were you mentioned that By But it was based on like you were using kind of recognizer there, right? Uh-huh. Right. Right. Yeah, it's I'm I mean yeah, it's different. But uh it's speech coding at least. I think so. Right. Yeah, sure. Band you mean? Right. With different I don't know. But maybe what we can already do is uh to decrease this uh this distance. We can do a Hilbert envelope approximation with one second. But then we can split that signal into, I don't know, ten ten uh segments with the one hundred milliseconds or even less, and we can apply some other technique for that, you know. Still Right. Exactly, exactly. Yeah. Well, th more less they don't care what's uh what will be the quality of the of the or the bit rate, they just want to get something new, you know. So if you get the v very uh low bit rate with a reasonable quality or really high bit rate, which is c again different, but with uh high quality, uh they would be happy with the both. So You know, on one side it's pretty good but on the other you don't know which way you should go 'cause there are many of them. And uh Right, right. Okay. Well I I will W uh do you want to mention your speech coding experiments? So you are saying that you're doing something i in India with uh So you know the sub mm like um more details? Oh yeah. Okay. Right, right. Right. I see. Yeah, but it's quite interesting with the even with th uh s current speech coding uh technologies. We are they are still trying to use k zap or those R_P_ based approaches. There is nothing new, more or less. And if I when I was uh listening the uh the talk of uh Milan Jelinek, uh he's the Czech guy, but he lives in uh in Canada. I don't know the name of the university. But they they have uh the pattern I think for CELP even. Or Um I don't know how it is exactly but they got very very famous for this for that CELP. What they did exactly I don't know, if something different a little bit or not, or they just keep those patterns or I don't know how it is exactly. Maybe Hynek will know much more. But uh when I heard those that presentation, they didn't do so much new. I mean uh it was last year and uh I think Hynek, he was asking wh so what's new that you are so famous with that and they n they said okay, we we know exactly how to do that. I mean you know, not to make any errors like in because everybody knows how to do that. But uh it's not so easy to implement it, right. So uh there is nothing so much new really like. Yeah. Right. Right. Exactly. Right. Right, ri right, exactly, exactly. But then they are s still using like error signal, which is going to be approximated by code book, right? And a linear prediction, which is use which is approximating just the spectrum of for for and everything that that's that's all. So still Right. Yeah, yeah. Right. Well, I hope that we still have a a lot of time for that because uh I think yeah, it's pretty interesting, yeah. For example when I was uh you know, harmonic voice modelling, that H_M_M_ system which is using used for synthesis more less. It's pretty interesting. I mean it it works it works well. Right. Right. Yeah, yeah, it is. You mean uh in sinusoidal uh modelling? Yeah. And but anyway, do you know exactly how it is done when you really have those M_F_C_C_ coefficients, which means magnitude spectrum, and then you are trying to reconstruct the speech? Without a phase. Because I I tried you know those th those papers. But s I'm little confused about it. I don't know how it works. But Which one? Yeah, that would be nice. Oh. You know, m but there are some algorithms which were quite uh Yeah, yeah, yeah. Yeah. Uh it seems to me, yeah, something like that. Like try You know what you can do um maybe. What you can do is uh take just the minimum phase of which you can get from a linear prediction, right? You know what I mean, minimum phase signal. And it sounds quite uh reasonably the two. But of course they are li it's not original at all. So I don't know how they do that exactly. No, I've no idea. Right. True, right. For n for Aurora we didn't do anything with that. Yeah, but we didn't do any speech recon re reconstruction. Yeah. Yeah, yeah, sure. Right. Right. Right. Right. You mean with this phase uh sure. Yeah. Yeah, they do some kind of reconstruction of speech. Uh yeah. Right. That's true, yeah. Right. Yeah. Yeah. So Yep. Yep. Mm-hmm. Mm-hmm. Sure, yeah. Okay. So how about you? Yeah. Yeah. You mean like channel and source coding together? Or no. Well I can imagine kind of like J_ PEG operations, which might be more less like it's source coding and then we also channel coding because we just smooth the or just I don't know. I don't know. Right. Right. Right. R right, right. I don't know. I don't know so much about s channel coding, like those Huffman coding stuff and, you know. I mean it's just standard. Yeah. They're just standard techniques. But Yeah, exactly. Yeah, yeah. I think so. H yeah. end. Okay. Thank you guys. Uh if you find some good paper which you might There was that fam fam waveform pro prototyping cor