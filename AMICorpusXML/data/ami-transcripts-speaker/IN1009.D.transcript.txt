So b maybe I'll go back to your questions. Um Yeah. Um Yeah. And this also um allows you to separate people. Um and the questions I did not talk about was uh going from location to uh identity of the person. Um That is quite different, you you need to use a signal you have separated and uh do the type of analysis I mentioned. Um from the spectrum you can transform the the magnitude spectrum and um um build model of the person. Um Yeah, pitch at least. But pitch is Pitch isn't is not enough sometimes. I it's a frequency, yeah, yeah. It's a frequency of your vibration here. Uh Yeah. And then it's transformed through the mouth, that's the usual model. Yeah. I yeah, um it's not necessarily done explicitly, but it's equivalent to that, yeah. So again, F_F_T_ is useful to do this type of analysis. Um Yeah, but it's quite personal. Uh Yeah. Yeah. Yeah, yeah. It it's an information equivalent to that. It's maybe n you don't need to do the whole uh complicated modelling, but No, no. Yeah, rate of speech is also possibility. Um how fast you speak, that's quite personal also. But it varies over time, um depending on emotion. That also might be interesting for you, detecting emotion. Yeah, yeah. And us yeah, yeah, so these measures are a way to quantify that. Uh p no. No, no it's not. What w w what is m what is more expensive is to um take the decision finally. So your decision can be for example uh who is it, or if the person moved, which is probably the most complicated thing, like the person goes away, then comes back ten minutes later, sits at a different place. Uh you will need to build statistical models of um the person identity using these measures. So the ones um he mentioned um I don't know if you're familiar with that. Yeah. Yeah. So um No. Yeah. S Yeah. All I was saying is that these different measures are a way to uh evaluate the identity of the person. So if with location all you can do is extract segments of speech, for example, but it will not tell you that these are the same person. It's just a location. Yeah. Yeah. Yeah, so that might be good for example for ten minutes, but then the person might move, or a different person might come. Yeah. It is. Well, unless sometimes somebody goes there or yeah. Yeah. Mm-hmm. Yeah. Yeah. Yeah. So it hmm. But that you can do with location, if it's only on the short term. On on the off-line yeah. I would say you might use these measures in a simple way if you do it uh on-line. Like um to give feedback. But uh you you mentioned that another side of your project is also to analyse off-line. So there you might want to use a We had a student here, he finished uh one or two years ago, but he left his software, and his software is precisely to do that to um cluster at uh another level, to cluster these small clusters of speech, uh group them by person automatically. Y no, from the these measures, pitch, etcetera. So um Yeah, exactly. So I would say from location at the lower level you can get small parts of speech, and then at the next level, possibly off-line, you can uh group them into um a speech segment. I'm hoping to have enough time to try um doing that before I finish my thesis. Um so if I manage to do some um uh practically usable software, I'll tell you. Uh in five, six months, abou approximately. More busy I would say. Yeah. So you said you want to do separation, um but ex exactly, yeah. Yeah. Okay. Okay. Ah, you want to do voice recognition. You might want. Okay. Okay. Yeah. So yeah, once you have locations it's not a big problem. Um Mm-hmm. No no, you should separate them first, yeah, yeah. So So the type of things I presented can lead to separation. Um it's only a very small step to add. Yeah, yeah. Although it might be, if you want to um ex extract these features like pitch and uh rate of speech, or energy simply, from each person. Um you might have to do some ba basic separation. 'Cause quite often people uh don't realise that they talk at the same time, um interrupt each other. So even if you don't want to recognise a speech fully, at least um you need yeah. It's okay. You can email later. Yeah. Um So Yeah. Uh Okay. A semantic context, yeah. Yeah. Yeah, then mm. Hmm. So it's uh Yeah, you could detect one word, yeah. Keyword spotting, yeah. So um Yeah. Yeah, I I'll just say uh if you want I can point to um three papers, um but no, I think it's better if I just send you the link, it's probably simpler. Uh one im is about this um sector based stuff, like uh the localisation and detection. One is about how to take the decision, that somebody's active or not. Um it sounds simple at first, you think you just put the threshold and that's it, but um the problem is uh the It no, you can do that. There's no problem, but i if you want your your system to work in different conditions, like cafeteria, library, um the environment will be quite different, so a single fixed threshold value might be a problem. S Yeah. So you can do that automatically, this kind of things. Um I don't know if you're doing that already, but uh Okay. So uh I have another paper which might be interesting for that for a single channel uh calibration. And I've code on-line, so for this particular one. And the last one I would say is um the clustering um to um yeah, the clustering of the different locations over time, so that you can get small clusters of speech. Um there are other ways to do it, but uh I think it's it's important because um in spontaneous speech all these words are quite small. So you need to do that uh adequately, yeah. But otherwise yeah, I'm done. Hmm. Yeah, yeah. Many small events basically, yeah. Yeah, basically uh I mean it depends uh Yeah, even if somebody says just yes. I don't know if it's important for you or not. It might be. Yeah. Yeah. Hmm. Yeah. Y Yeah. Yes. Um So I I'll send you links some of the papers are long, but you can just um briefly look, yeah. Um we can go and see Olivier, unless you want to talk about something else. Huh? Well, we can try. But uh We have yeah, we have O_C_R_, but maybe not on this computer. Yeah. That is good idea, yeah. It's a good idea. Yeah, yeah. Yeah. Once I I um coded the most expensive part in C_ just to see so you can have a mix of both. From Matlab you call C_ and back. But the day you want to do uh on-line real time stuff nah, I wouldn't wouldn't trust it.