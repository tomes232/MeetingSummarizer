Okay. Okay, so should I start? Okay. So I think it's better to first have a presentation of my work and then we can discuss uh with this crash in temp in temp uh what we can do uh for my future to to continue my research, because apparently I I will have serious problems, okay. So I will start with the presentation of my work. Mm. Okay. I start like this then. Okay, so it's uh my g work is generally about uh using posteriors in uh speech recognition systems and uh somehow enhancing the estimation of posteriors, getting new posteriors which are havi which are more informative by somehow integrating some extra knowledge like uh prior knowledge and contextual information related to the problem and then use this posterior estimation uh uh method uh for designing hierarchical uh speech recognition system. So in this hierarchical arg architecture I will be able to uh integrate the extra knowledge at the proper level of hierarchy, and I will be al also uh able to uh combine different kind of uh knowledge or sources uh sources of knowledge I have. Uh well as you know uh generally posteriors are estimated using uh neural networks and more specifically M_L_P_s in a speech recognition system, so uh time limited window of a speech signal is uh represented by some cepstral features, which are then processed by an M_L_P_ and it gives us some evidence as in the form of pos phone posteriors. Then we use these phone posteriors as features or as scores for for either just decoding or d uh uh n d training and inference training and then decoding. Uh but we know that uh in this uh in this case we are not able to integrate contextual information uh uh line contextual information, and we are not able to integrate the prior knowledge we can have about phone use or about uh words in the posterior estimation, so the main motivation is to see if we can integrate this kind of extra knowledge in the posterior estimation. So what is proposed to solve this problem is to use a uh what we formally use in H_M_M_ formalism, which is called gamma uh state posterior. Uh i uh as a posterior for uh training uh or decoding, so it's uh well as you know it's a state posterior probablility in a H_M_M_, which is defined as the probability of being in a specific H_M_M_ state at a specific time, having the whole observation sequence and the model. So whole observation sequence means having complete contextual information and the mod uh and the model can encode some kind of prior knowledge for us by means of uh topological constraints. Uh well you know it's uh this gam uh gamma posterior is written in terms of forward and backward H_M_M_ recursions, and actually one way to use this uh gamma posteriors is uh using these posteriors as some kind of newer scores for decoding. So in this case it will be uh similar to hybrid method. Um the the difference is that we do one more step, uh maybe I can explain it better there. So we do one more step here, and we uh here by means of another H_M_M_ we introduce some kind of uh prior knowledge and contextual information, we get better evidences than what i we initially had here, and then we do the uh decoding and the and s more informative posteriors uh uh instead of this one. So we are expecting to uh the system to perform better and more robust to noisy cases. Here you see uh some results uh and how uh how what is the effect of introducing uh reasonable prior knowledge, so different uh rows in this table are showing different level of noise and also clean speech, and different columns are showing different kind of posteriors or gamma posteriors. So uh the the first column is showing the uh our baseline system, which is getting estimate of posteriors out of M_L_P_ uh and then d using these posteriors for decoding. And the other columns are showing the performance of uh different kind of gamma, so uh gamma which is estimated using uh information about minimum duration of phonemes, about possible transition between phonemes and some kind some uh more prior knowledge like uh which wo like uh which word is composed of which phonemes and uh g uh gram grammatical knowledge ab uh about transition between words and things like this. So as you see, introducing more reasonable prior knowledge um will h help to have better performance in almo in almost all the cases. And here I compare the performance of the gamma base system with the standard H_M_M_ G_M_M_ system, which is based on uh doing decoding uh using uh likelihood as the scores, and the difference is that our system use uh is using posteriors for decoding, so as you see s uh it's working uh better than the standard H_M_M_ G_M_M_ system. And finally the conclusion is uh he here we saw how we can get uh some more informative posteriors by introducing extra knowledge like prior and contextual information, and then using this uh uh p posterior estimation method to design hierarchical uh speech recognition system which we're which which the goal is to have a better, more efficient and more robust system. So if you want now we can discuss about um uh the crash and the loss of data, so uh well I lost all the posteriors I was I uh I used as input uh for my system, so the gamma are somehow estimated or computed on top of posteriors. And now I don't have any posterior and uh probably the scripts generating that posterior, so what I can do okay. Okay. Okay. Gamma full model, but uh what about other ones and what about the f posterior, because because I I uh you know, I cannot uh stop my resea I I may do something else, you know, in future with this uh and well I need posteriors to Yeah. Uh no no, I don't have them there were all under temp. You you we have that because you uh stored them. So. Yeah. Yeah. Maybe maybe some other m uh P_H_D_ student should be hired to work on, you know, the generating gamma. Six, okay. Less context, what you mean? Uh Yes. Yeah. You mean a smaller context instead of this. Mm-hmm. Mm. Yeah. Yes. Yeah. Yeah, b well, even they can have some information which are not so meaningful or uh which are not related. Yeah well, but then I will have the problem to find the optimum amount of context. How much context should I take? Mm-hmm. Mm. Okay. Okay. Yeah, that's a good idea. That's reasonable. Mm. Yeah. Yeah. And and you don't have uh scripts for Ah, okay, you do you have just your, no? And what could happen if you don't even have your? Mm. Yes. N yeah, I uh for C_T_S_ Petr uh still I think have he didn't uh lose anything, so. Ah. Okay. Mm. Mm just uh po uh pi uh posterior estimated using P_L_P_ features for number, which I think we can we can rate it. Uh P_L_P_, they're also last. Okay. Mm-hmm. Mm-hmm. Mm-hmm. Okay. Yes. Uh nowadays not that one. There is another problem for uh verifying these results, because well for these results, you know, the the configuration should not well I also saved the configuration somewhere in the temp, so exactly how many stays for decoding and which kind of language model and things like this. I I think I can remember almost all of them, but f it's it's a bit uh uh stressful. Yeah, but h he doesn't. Uh y m yes. Lost. Mm-hmm. Okay. Yeah, so so as the conclusion there is no major problem except regenera yeah, which time for, I guess. Mm. Mm. Mm. Mm. Yeah, yeah. Yeah. Mm. Well, I also had the of generated posteriors or gammas or things like this, which I should regenerate, I have the uh scripts but uh well it takes time, it's C_P_U_ and regenerating all these things, but okay, it's okay. So there is no major problem except time. Deadline of two weeks for ICAS. Okay. Hmm. Hmm. T Ah. Well I I think w after this meeting we can t we can try together to regenerate this. Well uh P_L_P_s I think th they should be first regenerated, then posteriors, and if by the end of week we could have posteriors, then it's not that difficult, I can easily regenerate the gammas and do all the experiments again. Maybe it's a Uh mainly th there would be some experiment to check how the system is robust against these uh tuning factors like uh language mod uh language modelling, scaling factor language scaling factor and inversion penalty. This will be the main new issue, and uh well Yeah, the new thing in the paper, and well, some No in these cases, but Well actually actually this w this was not in the paper. I put it in the presentation, but it's not in the paper. Uh the paper was just for clean speech, but since I had the results before and I cannot copy these things, because I t uh I talked with Herve and he said okay, actually the numbers are not uh very reasonable because they are just thirteen P_L_P_ features and uh we have to have at least something which is known for people. I mean they are expecting something around ninety, eighty seven or uh something like this. Uh so I anyway, I had to re to redo all the experiments, but now it's a little bit more difficult, because before I had posteriors and now we have two more steps, P_L_P_s and and and posteriors, so. Yes, thank you very much. Thank you very much uh. Oh m I wanted I wanted to extend this uh well actually, the paper we wanted to write was uh for ICAS was something related to multi-stream gamma. But okay, okay. Uh will I I will explain. So tha my plan was to have two streams, and I I I well. Yeah. I so I I thought that okay I one stream will be P_L_P_ and the other will be delta P_L_P_s. So this was one part of experiment, so single stream, and then I wanted to combine deltas with this and have another table, so that was why. But actually because, you know, the numbers and the study is not sh i it's not showing uh strong results. Anyway, results are not very important, but they should be within a range of uh acceptable numbers. So then uh for now I think it's better to instead of doing P_L_P_ and delta P_L_P_, I can uh have single stream of thirty nine P_L_P_s, and then combine them with traps, just to have Yeah, thirty nine. Yeah yeah, yeah yeah. No no, it's Interspeech. The okay. These numbers are full P_L_P_ thirty nine, okay? But just to make things clear in the presentation, to show more steps Try yeah. Yeah, yeah. Even Even if you No Th Yeah. It's amazing that everything was under temp. Yeah. Yeah. Yeah, Sileye will be back and he's not in vacation, but he's in Italy. He flies to Senegal directly. Mm. Mm. And what if we have some day a fire in IDIAP, we will lose all the data. Mm I mean, but they have well I I think w they can and yeah, they can d you know, store it somewhere. But you know, here we can easily have a fire, because the everything is made of wood I think and it's small and Anyway, the good the conclusion is to have a back-up and uh and C_D_ at home. Mm. Yeah. Hmm. Mm. Hmm. Yeah. Mm-hmm. Yeah. Reverse. Okay. Thank you, thank you. You too.