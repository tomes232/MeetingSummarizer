Okay. Mm-hmm. Okay. Okay. Mm-hmm. Okay. Okay. Yeah. Okay. Yeah. Okay. Mm-hmm. Okay. Mm-hmm. Okay.. Ok okay. Mm-hmm. Mm. So do you know uh which way you give the feedback? Light or I saw something like that. Okay. Hmm. Hmm. Mm-hmm. Mm. Okay. Okay. Yeah. Maybe more complex, yeah. Yeah. So th Hmm. But yeah. To the border basically some distance? Or Okay. O okay. Obviously, yeah. Okay. Okay. Hmm. Yeah. Yeah. Okay. Right. Hmm. Mm. Okay. Mm-hmm. Okay. But don't yeah. Don't you think with a beam also you have less problems with the sheets? Or you don't want to do that. Yeah. Okay. Confusing, yeah. Hmm. Okay. No, it's a choice. Yeah.. Okay. Mm-hmm. Yeah. Mm-hmm. Okay. Yep. Okay. Yeah. But physically it's just uh something flat on the table again, yeah. Okay. Okay. Yeah. Okay. Hmm. Okay. Yeah, so it's different, but still uh yeah, it's same Okay. Okay. Yeah. Okay. Yeah. Mm-hmm. Okay. Mm-hmm. Okay. Mm-hmm. Mm-hmm. Yeah, yeah. Hmm. Right. Hmm. Okay. Right. Mm-hmm. Mm-hmm. Or too long. Oh, just kidding. Okay. Yeah. Yeah. Right. Mm-hmm. Yeah. Ah, so you ha you you might have multiple colours? Or yeah. Sorry, didn't get that. Yeah. Yeah. Alright. Okay. Yeah.. Mm-hmm. Right. Mm-hmm. Okay. Mm-hmm. Okay. Hmm. No, it's quite clear. So uh I guess you want to know what you could do with an array maybe? Mm-hmm. Yeah. Or yeah. Yeah. Yeah, it's good idea. Just give some questions uh Mm-hmm. Right. Mm-hmm. Mm. Mm-hmm. Okay. Mm-hmm. Yeah. Mm-hmm. You mean the top of the wave-form? Okay. Yeah. Oh Okay. Hmm. Hmm. Mm-hmm. Okay. Yeah. Yeah. Hmm. Okay. Mm-hmm. Yeah. Yeah, yeah. Okay. Separation uh Yeah. Hmm. Mm-hmm. Well you need a camera. Obviously. I mean will you have a camera? Maybe you can detect breathing. Yeah. Yeah, that you could do. Or on the table uh there should be well. Okay uh Okay. Mm. Well Okay. Mm-hmm. Okay. So you I think Guillaume said that's optic, something like that? Or Okay. So you you need a different you need a microphone with um a device inside, right? Ho how does it work? Okay. Yeah. Okay. Mm. Hmm. It's another fire-wire or not fire-wire, but um Okay. But concretely you would use that to get higher quality signals? Y that's all.. Yeah. Ah okay, okay. Yeah. Yeah. Hmm. Okay. And how Hmm. Hmm. You mean you meant eight kilo uh sampling frequency? Yeah. Uh we use sixteen. So that's eight kilo band-width. Sixteen kilo uh sampling frequency. It it's not bad. Uh it's quite decent. Um Mm f before answering the questions uh th there's also a point of uh precision of localization if you use an array. So if you use higher frequencies you can get more precise localization. But maybe you don't need it. Uh that I can't answer directly. Uh it depends on your set-up, you know. Um you have to test basically. Um Y you get uh the angle. The most precise one is the asymmet in the horizontal plane. Then you also get elevation. But it's not very precise. It's more of an indication. And radius is very bad. If you use a planar geometry like this one. Yeah. Um you can use multiple ones and do some um um triangulation. Eight, eight. These are only screws. Microphones are on bottom. Yeah, yeah. Mm-hmm. A cube? Okay. Yeah, then you might get uh better direction in elevation. But I'm not sure it's really relevant. Um no. So Uh if people move forward, yeah. Ah, the radius? Th then the r the problem is not the geometry, it's the um I you need more than one basically. With one you will only get direction. Microphone array. So Mm. Direction, yeah. Um Yeah. It's a different option, yeah. Um we haven't tried that because we are not going to have the special kind of table. More uh this is not a good example but we have like a box, just bring the box and put it. So it uh we could not consider that. But in your case it could be interesting, yeah. Unless people put something on the microphone. But um Yeah. Right. But that I'm I think after the meeting we can go and talk to Olivier about that. I'm not the person for hardware. Yeah. Yeah, I'll t I'll try to present uh I guess it corresponds to your questions. Yeah. So the the lowest layer would be the first two questions. Um you asked about how to detect um activity. Currently you're thresholding the t maximum of your wave-form, right. Ah, ah. Okay. And you're looking for a peak. Yeah. Yeah. Yeah. Hmm. Okay. Uh Yeah. Yeah. And your second question uh was about F_F_T_, what can be done with F_F_T_. So um the approach we're taking here is to answer both questions the same time. We use F_F_T_ to do detection. We don't use the wave-form, the raw wave-form. So um We split um we split the signal in small frames, like sixteen millisecond. Sixteen. Um each frame is taking thirty two millisecond of signal, just to give an idea. And there is a one frame every sixteen millisecond, and they overlap of fifty percent. Um Yeah. Each sixteen millisecond. Well th these are details. It's just to give an idea. Um Well it's uh the the c Because usually when you do F_F_T_, y if I'm getting into details, but you you apply um a window to avoid effect. So the beginning and the end it it i it's not crappy, it's just not very much rep represented because you apply um a window which has this shape, having window. So they're very yeah. No, I'm saying uh when you take your signal you take one frame, you apply the window, uh and the window is simply uh coefficients you give. And you give higher coefficient to the middle than to the extreme. So if you don't do overlap y you will lose information at the beginning and the end. Okay. But you don't have to do overlap. I mean uh it's um Hmm. Um C_M_U_, no? Is it from C_M_U_? Um uh yeah. Yeah, yeah. Right. Yeah, yeah. Yeah. F_F_T_ is only a tool. Uh um uh what we do release a phase domain analysis. We only use the phase between the microphones. Um Yeah, but also for detection. Yeah. Um we have a way so um I don't think I should get into details. But basically the beginning is your signal which you slice into frame. You do F_F_T_ on each mic. And the end is um a number of uh frequency beams which are used by each person, to uh explain roughly. S so when you speak, speech is wide band. So um the more active you are the more band-width you use. So you will get a large value of band-width for people who speak. And uh for the others it will random. It will be a small value. Or just background noise. And so uh Yeah. 'Cause one problem if you use energy based methods, which is probably more uh the thing you've been using so far, is that it's not um quite related to location. So you can have um uh for one person you can have uh a high energy signal which is difficult to locate, and visa versa. Um I think in your case you're quite interested in the location. So I would advise to um use more uh phase domain methods. Um Once you have the fifty, for each frequency you have uh the magnitude and the phase. So you can compare the phase of the microphones. And this is directly linked to the direction of the person. Um Sometimes we use it, but not it's not the first thing we use. I know it's a bit counterintuitive. But um maybe I'll go t to the board. Yeah. Okay. R right, for a single channel it's not very meaningful. But here it's relative phase between the microphones. So uh I'll just try to um s summarise. No, that's what I don't do. Um this would be valid for uh like speech recognition with a single channel. That would be a very good idea. But if you choose to use multiple channels um let's say you have four of them, with F_F_T_ you can just uh, as I said, l look at the phase between the microphones at a given frequency. Um it is linked to this value, yeah. Uh basically the time you're mentioning is this value. And this is the frequency. And this is an angle in radians. So uh F_F_T_ gives you a measure of these values. Uh this, I can point to a paper, uh I don't think this is the right place to explain everything. But will give you if you look at your table, uh what we have developed here is an approach where um th uh you divide the space in sectors. For example ten sectors around the table. And uh in each sector you will get the value. No. It's uh application dependent. For example um Well this is not. And on this one you could have a large value. On on on those ones, small values. Uh these are number frequencies which we estimate with several steps from these measures. So to conclude what we are doing is uh we estimate how much of the frequency spectrum you are occupying when you speak, or I am occupying in this direction when I speak. And it turns out that um this is quite good to do uh detection and localization at the same time. Bec because you know in a sector space there is uh uh this much activity. Yeah, yeah. Um more recently um I've worked on uh um prolongating this with a more precise direction evaluation to know where in the sector the person is. So that uh that's not much work. Once you have done this, this is can be this can be done quite quickly. Then you Yeah, y well I I use a value. But then you'll get two large values. Yeah. So No. Just direction. Yeah. Well, f yeah, I it's not uh i it's an inherent problem to the geometry you use. You can for example, if you use another array, uh you can intersect lines of direction. Uh Mm maybe. Uh uh I w mm I wouldn't trust it too much. Classically, what you do is you extract the signal of the person. Um one interesting thing is that these numbers are not uh arbitrary things. They represent the number frequencies where a given person is dominant. But when you have two of them, which might be interesting for separation, you know already when you have done this processing uh w which part of the frequencies of the spectrum um belongs to this person and to that person. And then it's easy to separate the signals. Um both. It's it's more an instantaneous um this is still instantaneous. This is for one time frame. If you look at all your frequencies for example uh zero to four kilohertz, um you can split it and say uh all these parts belong to person one here. And uh all the other parts belong to the other person. That's correct. But then uh you can look statistically it wi it will be negligible um because the r of uh of the difference level. Yeah. It's uh you can listen to it, yeah. And then you can do some uh maybe higher level um analysis where you get the pitch of the person or This Yeah, yeah. And this is Exactly. Yeah. Then it's uh random. And that's why you get these values uh which are random. Yeah. Yeah, but this is very rare. And when it happens, one is always masking the other in practice. So um Yeah. No no. But uh I've I've seen quite a few papers I I've n not done it myself. I'm really on the lowest level. Um but uh once you have done this, as I said, you can uh separate the signals and um do do processing. Uh so uh you can get pitch, rate of speech. That's quite easy. Pitch um the uh uh timbre en Francais. Um so uh for different person this might be quite different. At least for male females. And uh rate of speech. Like if somebody is talking very uh in a very energetic manner, it might be quite fast. Uh or just energy also. One Yeah, also. Um that might be an issue with people are bringing laptops. Um They will b yeah. They might be detected as another another source. Uh so you would have to uh classify the sources as human or machine. But again, yeah, I think once you see the spectrum, if it's just pure and stable uh Also yeah, if if there's no pitch. So uh Yeah. Yeah. So all will go and be detected there. Yeah. So w what you're mentioning is a pain for us. But for you it might be 'cause we're only interesting in getting the speech. But for you it might be quite uh quite good, yeah. So I've to avoid uh filtering and smoothing. 'Cause as soon as you do that um you exclude some of the information. So it's better to keep it for the latest stage. So um um on top of this there's another part uh which is more linked to the tracking. All this was for one time frame. So um Yeah, you can play with it. Um in speech it's uh stationary over ten, twenty millisecond. And we make a stationary assumption, a local stationary T_ assumption um which allows you to use F_F_T_ and blah, blah, blah. Uh now in spite of that I know some people use much longer windows, which is not a problem. But Uh it's a bit too much I think. Uh like some very small words, like yes, they might be two hundred millisecond or three hundred millisecond. Um Yeah, they might be blurred with uh silence. So yes. You you might have to play with it just to save processing time, like use slightly longer frames. Yeah, at m at most, yeah. Um Simply because I've used one hundred as a minimum length of a speech word. Yeah, so. Um now assuming you have done this for each time, i if this is your detail or I should use a different Um if this is your asymmet at each time you get a direction. So asymmet is your direction in horizontal plane. It's an angle. Like north, south, east, west. And Yeah. No no, of this is uh really different. I'm just saying that uh once you have done this for a given time frame you can have a direction of the person, at least in terms of sector. And it's also possible to give a more precise direction quite quickly. So uh this was kind of the lowest layer. Now this is a layer just above it which might interest you. Um if you repeat that over time you will see patterns um for example uh at two different locations. Two different person will speak. So you can cluster those. And you will see that uh if it's long enough it's some significant event. Um this can be done quite cheaply, yeah. Yeah. Yeah. A cost. Yeah, th Um well I use Matlab. So it's not perfect. It's like three, four Yeah. But not everything is uh um simple linear. Especially this part. It's definitely not linear because you're looking at a maximum energy in a frequency, kind of. The most expensive part is here. With Matlab I have three, four times real time. Um you can do sub-optimal processing and uh for example here I'm considering all possible pairs of microphones, uh which is twenty eight, and the processing is directly um r proportional to that. So um you can save on that. But then you lose a little bit on precision. Also I I'm using all the small frames with fifty percent overlap. I don't think you really need absolutely to do that. It's not that good in terms of uh direction. Um Yeah, I would be careful with that. Like five, six is uh decent. Uh six I would say, yeah. Eight, yeah, uh I get down now to one, two degrees uh root mean square error. Uh so you might not need that. That's what I mean. Might not be Um Yeah. Yeah. Yeah. Yeah. Yeah. So it could be sufficient to uh, yeah, define enough sectors and No. No. So it's arbitrary. I use twenty degree sectors. Uh 'cause I had to choose a value. But it's up to you. Um Yeah. Yeah. Um So that's another way, yeah. It it's almost like having a lapel, yeah. Um Yeah. I think it's not necessarily a bad idea, actually. Um Well uh If you are able to calibrate your microphones um the ones who are closer to the person will get more energy. Um so you can compare that. It's possible. So Yeah. Um I have experience with that. Um on the side I've done some single channel work which can maybe help. Um 'cause uh it seems to me that you are not definite on the geometry, right? Yeah. Um m this part is quite specific to a microphone array where like they are concentrated in uh some place, like in the middle of the table. Yeah. Yeah. Yeah. But you can kind of come back to that also. Um Uh F_F_T_ also. Yeah, yeah. R right. Yeah, yeah. It has to be as good as possible. Yeah. Yeah. True. Yeah. We can also consider directional microphones. You know no. Um so you can uh their pattern is uh not uh the same uh depending on the direction where the person is. So for example if there was a directional microphone pointing there you would get most of my energy but less from you, et cetera. You can also do microphone arrays with directional microphones. Uh um might not be relevant. But um Uh More or less. It's it depends on what you want. I mean uh I don't know. Yeah. They're o yeah, omni-directional, yeah. M uh I guess so. It's the same, yeah. Exactly the same, yeah. Yeah. Yeah, yeah. Quite expensive. Yeah, they are um high quality mics. Uh I think we can leave this question for Olivier. Yeah. No, no. Y you would uh assume Uh you would neglect it. The time delay is is very small. It it's only used for uh getting the a direction when you have a microphone array. But in that case it's not relevant. Um you would assume that they are roughly synchronised, not necessarily very precisely, and um compare the energy levels. But I have no experience with that. Um Now I don't know, you don't want to use ah, it's almost okay. Yes.