Yep. S so Joel is going to talk. That's mine. Well, may from different point of view. But Yeah. Right. Let me just tell us so what you know already about uh, I don't know, how far you are with the s features. Or So you know s something like that. Mm-hmm. But t what Christos was doing. Right. Yeah. Mm-hmm. Mm-hmm. Mm-hmm. Yeah. What yeah, yeah. We shouldn't smile. Right. Yeah. Yeah, but I'm using that for different different reason, right. So it's uh speech coding. So uh what is the task is usual just take the speech of course somehow to encode it into as as small number of beat as possible and with a reasonable quality of course. And again to e uh decode it. And I'm using F_D_L_P_ for that, still playing with uh more less one second long segments. So just dividing the speech into one s one second frames doing D_C_T_. It's just the standard wor of work. And then doing some compression and computation of yeah, yeah yeah, sh oh, yeah. But you are doing the same, no? Yeah b yeah yeah you take the the D_C_T_ and you just divide it into several sub-bands, frequency bands with a different uh I d I do. You mean No, no, no. No. I don't do. Yeah, just one second with without overlapping. But in frequency domain there is a overlap. Because you can choose which filters you want, more less, or just trajectories of those bands. So there is overlapping. I'm using those Gaussian filters or classical those those TRAPet trapezoidal like in uh M_F_C_C_s, right. And then processing each f yeah, P_L_P_s. Okay, tr triangulars. That one. Then I'm doing s doing uh independent processing of each frequency band. So I'm computing that Hilbert envelope, which is just the envelope of some temporal trajectory. And more or less you can divide this into a Hilbert envelope, Hilb Hilbert carrier. We use something like L_P_, a linear prediction envelope. Auto-regressive model and excitation signal. Yeah, so those are two parts or items you need somehow to encode if you want again to get original speech or reasonable quality. And yeah, there is some compression factor, which is again when you're computing that auto-regressive model from F_D_L_P_. You can compress the spectrum somehow in in such a way that you rather um preserve those even also those dips, not only peaks in the spectrum. And it sounds better for some kind of speech signals. So it's kind of logarithm when you use logarithm for M_F_C_C_s, right. So it's again compression factor, something like th and but then you have to uncompress it again of course to get back the speech. And there other other things which I'm doing. But it's not related to speech recognition so much, or but Well Right, right. Well, it's yeah. Sure, sure, I know. I mean it's more or less the same approach, right. There is m uh just more right, right, right. Yeah. With what? Yeah yeah. Sure. Number of bands and You know, that's the problem for speech coding. Because I don't have results like in speech recognition. So of course I have to listen it and and s well so now what I'm using are fifteen bands, which seems to me fit fifteen frequency band, which seems to me quite reasonable. We can go down till like twelve and still okay I would say. But then you start hearing difference. Or also that's another problem. Once you can go down with frequency bands, then you will have much uh more c uh complicated data. Uh let's say excitation signal, or that carrier which yeah because broad bands, right. Yeah, maybe like that. No? So there is more and more s uh frequency components let's say or something like that in one broad band. So No. L_P_C_ will maybe. But then you have still another part, sometime something like a source and a filter. So when you are doing speech coding or Yeah. Why? I don't know now. It's quite long. Well I mean it's it's the same like when you are doing L_P_ L_P_ synthesis, right. So you've got source signal. I don't know. Source. Uh Yeah. And then there is some filter, which is that one divided by A_ Z_. And that's and that's it. And the source can be a noise signal or it can be some uh sequence of uh what is that? Pulses, right. This is yeah. So and it's more less or less the same what I'm doing. So this is some envelope, which is in our case related to Hilbert envelope. And this is a source signal which is Hilbert carrier. Right. Right. Exactly. Yeah. So this is now going to be frequency. Yeah. So more or less if we uh can we can plot it. So what we can see is some Hilbert envelope like this. And then there is that Hilbert carrier. Or this not Hilbert carrier. But this is the signal which we get from one di one frequency band. So you compute D_C_T_, right, from signal? Yeah yeah, exactly. And what we get from that is this Hilbert envelope, right. And the second, which should be that carrier should be something like this. It's just really close to cosine we m we might see if we do it do it properly, right. And this is what you also have to somehow transmit, or at least try to transmit in order to get Right, right. Right. No, I don't need L_P_C_. No, no. This is a residual for me. Yeah, I'm just wan I just want to transmit this signal right. It's and what you need is this envelope and this one carrier. And you again get the same signal, this this this shape, doing I_D_C_T_. Putting everything together. Right. But if you take a look for example for a s if you have a very g good music signal, which is very uh periodic you can really see something like there is one peak and And frequency more or less doesn't change. It's uh related to uh that frequency of the broad band or how it's called. If you add those filters, which are uh wider and wider this is that centre frequency which is somehow related to this one. So then you can transmit uh just fe It's worse and worse. Don't then you don't see any anything like cosine. But Right, right. Everywhere. It sounds like L_P_C_ when you excited by noise. It's better, I would say. Uh better quality. Definitely better quality. It lower bit rate. But that's a problem. So so ... Yeah, sure. Objective measure, well, it was some those uh distances, spectral distances well, Edinburgh saw probably. So well, I mean I h Alright. Yeah. Sure. I see. Right. Yeah. Yeah, yeah. Also there are papers about it that f if you have like twelve frequency bands it's somehow optimal. Compression is only to really to somehow feed that uh Hilbert envelope to yeah. Yeah, yeah. You can model it better. There is no echo or something like reve reverberance in the signal if you really go down with that compression factor to like zero point one, something that. Zero point one. So Right. It's it's s right. And it's still yeah. Yeah, you just preserve something different little bit. Let's say in R_S_S_. Yeah. I think Hynek has got ma many papers or some papers over that. So Oh. In I think I read it. Right, more or less. Right. Exactly. Yeah. Well I think you can really take those papers from uh Marius about F_D_L_P_. They are that's really enough on What is SAPA? Mm-hmm. Mm-hmm. Just something. Right. Approaches. Mm-hmm. But there are also reports from IDIAP I think. At least two reports from Marius seem to me. Yeah, they are more less they are same like. Mm. Mm-hmm. Yeah, yeah. Right, right. Yeah, yeah. Yeah. Yeah, definitely. Sometimes unreadable I would say. It's quite difficult, but yeah. Mm-hmm. Mm. Mm-hmm. Yeah, I think this year a lot uh Interspeech there was one paper. But it was regarded to speech recognition somehow. Y yeah, yeah. It was not something like speech coding or that D_C_T_ transforms. N nothing like that. So Right. Right. Mm. Maybe yes. Maybe no. I don't it's hard to say. Now it's not so bad with that if you really write it f well. And he did. I think so. Sure. R right. Yeah. Yeah. Yeah. Yeah. Whatever. That's not important. Uh .. Oh yeah. Sure, it is important for this case. But still Right. Yeah, and definite. November? November. What are you going to t talk or to teach? It's just that perceptual stuff and Mm-hmm. Do you already know how many students you have? No. Oh it's graduate for graduates. Well I think Guillermo was thinking about. And Hmm. Well I would like to go there, but not just for credits. Just maybe to hear something new. Mm-hmm. Right. Mm-hmm. Oh, sure. A any I think so. Why you are you doing this. Good question sometime asking Right. Thank you.